#### kafka 只是消息引擎系统吗？

Apache Kafka 是消息引擎系统，也是一个 **分布式流处理平台** （Distributed Streaming Platform）。

Kafka 在设计之初就旨在提供三个方面的特性：
```
提供一套 API 实现生产者和消费者；
降低网络传输和磁盘存储开销；
实现高伸缩性架构。
```

在大数据工程领域，Kafka 在承接上下游、串联数据流管道方面发挥了重要的作用：所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。

这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？

基于这个考量，Kafka 社区于 0.10.0.0 版本正式推出了流处理组件 Kafka Streams，也正是从这个版本开始，Kafka 正式“变身”为分布式的流处理平台，而不仅仅是消息引擎系统了。今天 Apache Kafka 是和 Apache Storm、Apache Spark 和 Apache Flink 同等级的实时流处理平台。

除了消息引擎和流处理平台，Kafka 还有别的用途吗？

当然有！你能想象吗，Kafka 能够被用作分布式存储系统。Kafka 作者之一 Jay Kreps 曾经专门写过一篇文章阐述为什么能把Kafka 用作分布式存储。不过我觉得你姑且了解下就好了，我从没有见过在实际生产环境中，有人把 Kafka 当作持久化存储来用 。

对于kafka streams相对于其他大数据流式计算框架的优势的第一点不是特别理解。spark或者flink读取消息之后再写回kafka，可能会导致多次写入kafka，老师能不能解释一下什么情况下会多次写入kafka？


作者回复: 不用拿Flink或Spark举例。我们就说一个普通的producer程序：producer需要接收到broker发送的response才能认为发送成功，如果response在传输过程中因为网络抖动丢失了或超时了（这种情况非常常见）而broker实际上已经写入了该消息，那么producer就会认为发送失败从而尝试重新发送，这就可能造成同一条消息被发送了多次。

流处理?

流处理是一种重要的大数据处理手段，其主要特点是其处理的数据是源源不断且实时到来的。
